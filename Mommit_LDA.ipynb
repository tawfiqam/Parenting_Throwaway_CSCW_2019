{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:07.478964Z",
     "start_time": "2020-02-20T00:22:04.341141Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tammari/Desktop/DaskTest/env/lib/python3.6/site-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
      "/Users/tammari/Desktop/DaskTest/env/lib/python3.6/site-packages/scipy/sparse/sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import glob\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.cluster import KMeansClusterer, euclidean_distance\n",
    "from numpy import array\n",
    "from pprint import pprint\n",
    "import re\n",
    "import scipy.stats as stat\n",
    "from os.path import basename\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "from empath import Empath\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.externals.six import StringIO  \n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import  cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import seaborn as sns\n",
    "from pycebox.ice import ice, ice_plot\n",
    "import operator\n",
    "from nltk import stem\n",
    "from nltk.stem.snowball import *\n",
    "from nltk.stem import PorterStemmer\n",
    "import dask\n",
    "import datetime\n",
    "import time\n",
    "from pprint import pprint\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "import os\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(filename='lda_model_Mommit.log',format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "\n",
    "def Tokinization(document):\n",
    "    document = \"\".join(document)\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    intermediate = tokenizer.tokenize(document)\n",
    "    return intermediate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:19.565926Z",
     "start_time": "2020-02-20T00:22:07.482172Z"
    }
   },
   "outputs": [],
   "source": [
    "df= pd.read_pickle('Parenting_cleaned.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:21.244112Z",
     "start_time": "2020-02-20T00:22:19.568395Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a Mommit Data Frame\n",
    "Mommit = df[df['subreddit']=='Mommit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:21.256825Z",
     "start_time": "2020-02-20T00:22:21.246968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading the Mommit Cleaned dataframe...\n",
      "**************************************************\n",
      "and for a test...\n",
      "1038051                                                 love\n",
      "1038053                                                 weed\n",
      "1038054    use money buy babi gift basket call stork bask...\n",
      "1038057    throw plan go sure could get pregnant first mo...\n",
      "1038058    go start tri get pregnant month someth beyond ...\n",
      "Name: clean_body, dtype: object\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "print('reading the Mommit Cleaned dataframe...')\n",
    "print('*' * 50)\n",
    "print('and for a test...')\n",
    "print(Mommit.clean_body.head())\n",
    "print('*' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:26.338405Z",
     "start_time": "2020-02-20T00:22:21.258888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grouping into dcouments\n"
     ]
    }
   ],
   "source": [
    "print('grouping into dcouments')\n",
    "CompleteThread = []\n",
    "CompleteThread = Mommit.groupby('link_id')['clean_body'].apply(list)\n",
    "#running for the rest of the data\n",
    "processed_threads = []\n",
    "#creating threads for each of the users\n",
    "for thread in CompleteThread:\n",
    "    #Preprocessing each of the threads\n",
    "    processed_threads.append(Tokinization(thread))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:44.432292Z",
     "start_time": "2020-02-20T00:22:26.340763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the documents is...\n",
      "17399\n",
      "**************************************************\n",
      "the first document is...\n",
      "['childless', 'choic', 'year', 'still', 'especi', 'fond', 'peopl', 'kid', 'kind', 'hard', 'like', 'believ', 'readi', 'tri', 'child', 'eight', 'year', 'fantast', 'support', 'partner', 'knew', 'would', 'great', 'dad', 'want', 'kid', 'badli', 'never', 'heartbroken', 'feel', 'readi', 'mom', 'daughter', 'decis', 'made', 'lightli', 'scare', 'throughout', 'entir', 'pregnanc', 'would', 'aw', 'parent', 'mess', 'littl', 'three', 'seem', 'pretti', 'wellmet', 'husband', 'bare', 'went', 'whirlwind', 'romanc', 'involv', 'lot', 'sex', 'never', 'care', 'thank', 'pass', 'std', 'hiv', 'test', 'told', 'kid', 'born', 'hypospadia', 'googl', 'risk', 'pco', 'know', 'time', 'continu', 'use', 'protect', 'total', 'four', 'year', 'went', 'diet', 'exercis', 'regim', 'lost', 'pound', 'start', 'ovul', 'boom', 'got', 'pregnant', 'unexpectedli', 'alway', 'said', 'okay', 'never', 'kid', 'thought', 'secretli', 'would', 'cri', 'night', 'wish', 'could', 'b', 'e', 'mother', 'cynic', 'hate', 'everi', 'pregnant', 'woman', 'saw', 'glare', 'everi', 'babi', 'god', 'bad', 'becam', 'pregnant', 'panick', 'idea', 'go', 'good', 'enough', 'mother', 'husband', 'marri', 'year', 'got', 'pregnant', 'alway', 'told', 'never', 'want', 'kid', 'happi', 'pregnanc', 'got', 'first', 'earli', 'ultrasound', 'week', 'feel', 'chang', 'instantli', 'scare', 'ye', 'excit', 'daughter', 'week', 'old', 'love', 'life', 'incred', 'thing', 'worri', 'money', 'bare', 'poverti', 'line', 'worri', 'provid', 'plan', 'get', 'second', 'possibl', 'third', 'job', 'go', 'back', 'work', 'octob', 'answer', 'question', 'initi', 'want', 'kid', 'time', 'went', 'want', 'plan', 'babi', 'damnit', 'glad', 'happen', 'next', 'babi', 'choos', 'one', 'plan', 'better', 'equip', 'financiexactli', 'like', 'mom', 'never', 'like', 'kid', 'daughter', 'love', 'complet', 'sure', 'want', 'kid', 'turn', 'like', 'entertain', 'idea', 'realli', 'sure', 'excit', 'fact', 'even', 'entertain', 'idea', 'made', 'decid', 'go', 'ahead', 'felt', 'might', 'reach', 'point', 'regret', 'never', 'kid', 'daughter', 'honestli', 'total', 'sure', 'want', 'mom', 'hold', 'babi', 'arm', 'deliveri', 'room', 'stay', 'home', 'still', 'work', 'part', 'tim', 'imagin', 'everi', 'day', 'never', 'imagin', 'ever', 'feel', 'waymet', 'husband', 'knew', 'want', 'children', 'famili', 'though', 'alway', 'want', 'adopt', 'older', 'marri', 'never', 'want', 'alway', 'love', 'babi', 'kid', 'never', 'tri', 'figur', 'plan', 'happi', 'clam', 'happenwant', 'kid', 'chang', 'mind', 'boyfriend', 'year', 'point', 'child', 'parent', 'chanc', 'grandkid', 'realli', 'thought', 'til', 'slowli', 'warm', 'idea', 'decid', 'gonna', 'happen', 'go', 'kid', 'turn', 'want', 'first', 'happend', 'second', 'never', 'babi', 'crazi', 'decid', 'kid', 'right', 'choic', 'usfinal', 'admit', 'someth', 'want', 'mayb', 'sound', 'odd', 'isnt', 'stori', 'set', 'feel', 'realli', 'talk', 'anyon', 'hope', 'dont', 'rambl', 'get', 'point', 'love', 'school', 'love', 'famili', 'want', 'right', 'mind', 'meant', 'person', 'goal', 'alway', 'came', 'first', 'excel', 'student', 'get', 'marri', 'career', 'still', 'rememb', 'night', 'told', 'husband', 'want', 'children', 'soon', 'alway', 'said', 'oh', 'yeah', 'want', 'kid', 'know', 'someday', 'absolut', 'bawl', 'like', 'babi', 'like', 'failur', 'want', 'kid', 'year', 'sex', 'talk', 'parent', 'protect', 'year', 'hear', 'women', 'judg', 'women', 'pop', 'babi', 'mistak', 'fell', 'away', 'felt', 'asham', 'let', 'mani', 'outsid', 'influenc', 'color', 'way', 'want', 'live', 'life', 'unhappi', 'wait', 'educ', 'marriag', 'career', 'point', 'admit', 'would', 'make', 'great', 'parent', 'would', 'happi', 'rolehusband', 'came', 'kid', 'singl', 'dad', 'twin', 'toddler', 'zero', 'doubt', 'doubt', 'good', 'enough', 'mother', 'kid', 'awar', 'choic', 'whether', 'marri', 'put', 'posit', 'kid', 'howev', 'adopt', 'first', 'come', 'ask', 'juic', 'curl', 'lap', 'bring', 'dinosaur', 'play', 'birth', 'mother', 'train', 'wreck', 'lost', 'custodi', 'visit', 'due', 'mental', 'health', 'abus', 'neglect', 'issu', 'rare', 'call', 'mom', 'instantli', 'dub', 'bree', 'daddi', 'bree', 'said', 'ask', 'bree', 'hard', 'doubt', 'could', 'two', 'littl', 'peopl', 'happen', 'obvious', 'littl', 'piec', 'man', 'love', 'flat', 'decid', 'want', 'mother', 'hardli', 'realiz', 'dad', 'fell', 'love', 'also', 'made', 'decis', 'let', 'mother', 'could', 'brave', 'hell', 'least', 'could', 'meet', 'halfway', 'end', 'social', 'put', 'ton', 'pressur', 'parent', 'right', 'everi', 'child', 'also', 'person', 'plish', 'rais', 'done', 'parent', 'get', 'everi', 'singl', 'thing', 'right', 'parent', 'kid', 'meet', 'somewher', 'middl', 'work', 'togeth', 'learn', 'super', 'mom', 'made', 'okay', 'nine', 'year', 'old', 'mother', 'half', 'live', 'regret', 'thingknow', 'boyth', 'realli', 'fenc', 'whether', 'want', 'kid', 'took', 'long', 'time', 'realli', 'readi', 'kid', 'even', 'sure', 'could', 'start', 'bodi', 'realli', 'weird', 'stuff', 'warn', 'might', 'abl', 'get', 'pregnant', 'without', 'help', 'look', 'meant', 'ivf', 'etc', 'said', 'fuhgeddaboutit', 'want', 'kid', 'turn', 'life', 'upsid', 'drive', 'everybodi', 'crazi', 'drug', 'temperatur', 'take', 'sex', 'right', 'time', 'worri', 'funniest', 'thing', 'decid', 'never', 'kid', 'probabl', 'ok', 'got', 'pregnant', 'grant', 'parent', 'easy', 'nobodi', 'choos', 'child', 'special', 'need', 'hardest', 'part', 'learn', 'deal', 'boyth', 'issu', 'particular', 're', 'examin', 'felt', 'first', 'found', 'adhd', 'broke', 'cri', 'thought', 'meant', 'stupid', 'possibl', 'addict', 'medic', 'rest', 'life', 'turn', 'without', 'yeah', 'harder', 'never', 'kind', 'person', 'take', 'easi', 'way', 'stubborn', 'get', 'sure', 'help', 'littl', 'year', 'half', 'later', 'find', 'asperg', 'mean', 'suspect', 'long', 'time', 'asperg', 'root', 'issu', 'speech', 'chronic', 'low', 'muscl', 'tone', 'inabl', 'make', 'friend', 'social', 'easili', 'etc', 'hammer', 'came', 'even', 'though', 'expect', 'it', 'i', 'upset', 'got', 'though', 'came', 'term', 'took', 'good', 'six', 'month', 'least', 'easi', 'prepar', 'kind', 'thing', 'happen', 'nobodi', 'write', 'expect', 'type', 'book', 'somebodilike', 'told', 'mom', 'would', 'never', 'kid', 'pretti', 'much', 'stuck', 'kid', 'unpredict', 'expens', 'way', 'much', 'respons', 'turn', 'instinctu', 'one', 'day', 'like', 'cool', 'want', 'babi', 'light', 'switch', 'think', 'part', 'could', 'afford', 'one', 'without', 'partner', 'marri', 'guy', 'want', 'children', 'felt', 'stabl', 'enough', 'rais', 'kid', 'instinctu', 'readi', 'super', 'peopl', 'kid', 'develop', 'level', 'patienc', 'toler', 'never', 'kidone', 'took', 'pregnanc', 'test', 'twic', 'second', 'one', 'came', 'back', 'posit', 'kind', 'like', 'oh', 'shithusband', 'said', 'oh', 'shit', 'show', 'posit', 'made', 'husband', 'go', 'buy', 'real', 'test', 'first', 'one', 'dollar', 'store', 'home', 'pregnanc', 'test', 'second', 'time', 'think', 'first', 'one', 'right', 'el', 'cheapo', 'brand', 'lolnever', 'thought', 'kid', 'much', 'like', 'children', 'understand', 'women', 'went', 'nut', 'babi', 'husband', 'four', 'year', 'old', 'son', 'ex', 'girlfriend', 'help', 'take', 'care', 'made', 'want', 'child', 'got', 'engag', 'husband', 'feel', 'want', 'kid', 'start', 'chang', 'want', 'creat', 'child', 'him', 'a', 'product', 'love', 'two', 'daughter', 'plan', 'love', 'anyth', 'older', 'daughterfunni', 'caus', 'opposit', 'took', 'clearblu', 'test', 'morn', 'got', 'immedi', 'posit', 'afternoon', 'buck', 'bought', 'cheap', 'o', 'dollar', 'store', 'test', 'immedi', 'came', 'posit', 'well', 'six', 'week', 'pregnant', 'time', 'test', 'pretti', 'accur', 'would', 'tri', 'get', 'pricier', 'one', 'though', 'start', 'cheap', 'one', 'alway', 'chosen', 'magic', 'age', 'could', 'settl', 'kid', 'marri', 'husband', 'three', 'year', 'decid', 'want', 'give', 'go', 'set', 'date', 'start', 'month', 'road', 'plan', 'good', 'month', 'adult', 'fun', 'travel', 'get', 'system', 'guess', 'great', 'decid', 'kid', 'day', 'book', 'non', 'refund', 'ticket', 'vega', 'found', 'pregnant', 'marri', 'year', 'two', 'littl', 'girl', 'second', 'child', 'snuck', 'schedul', 'vasectomi', 'actual', 'appoint', 'husband', 'vasectomi', 'month', 'old', 'ta', 'darememb', 'quit', 'lie', 'want', 'kid', 'lie', 'realiz', 'tire', 'wait', 'husband', 'finish', 'school', 'could', 'even', 'begin', 'think', 'kid', 'nope', 'sound', 'oddthink', 'realli', 'pregnant', 'morn', 'sick', 'yeah', 'hubbi', 'observ', 'would', 'end', 'like', 'one', 'chick', 'know', 'pregnant', 'lolhear', 'symptom', 'thought', 'get', 'period', 'bloat', 'hell', 'tit', 'three', 'time', 'normal', 'size', 'irrit', 'pissi', 'thing', 'occur', 'week', 'get', 'period', 'two', 'week', 'come', 'began', 'wonder', 'start', 'get', 'super', 'sensit', 'smell', 'seem', 'eat', 'red', 'meat', 'nausea', 'start', 'miss', 'period', 'mine', 'irregular', 'due', 'pco', 'two', 'year', 'normal', 'pregnanc', 'last', 'thing', 'mind', 'girl', 'work', 'told', 'take', 'test', 'took', 'prove', 'pregnant', 'lol', 'joke', 'palon', 'dork', 'ossim', 'internet', 'high', 'fivefelt', 'much', 'fact', 'mist', 'time', 'vagu', 'rememb', 'say', 'thing', 'parasit', 'gross', 'babi', 'got', 'marri', 'seven', 'year', 'pass', 'happi', 'content', 'part', 'felt', 'like', 'someth', 'miss', 'slowli', 'slowli', 'start', 'feel', 'desir', 'primal', 'desir', 'start', 'pay', 'attent', 'got', 'husband', 'board', 'wham', 'got', 'pregnant', 'first', 'tri', 'freak', 'babi', 'fell', 'love', 'still', 'love', 'peopl', 'kid', 'ador', 'infinit', 'fascin', 'amaz', 'love', 'sure', 'annoy', 'piss', 'peopl', 'someth', 'happen', 'kidaww', 'amaz', 'post', 'made', 'tearabsolut', 'bawl', 'like', 'babi', 'like', 'failur', 'want', 'kid', 'endless', 'demonis', 'natur', 'biolog', 'urg', 'though', 'suppress', 'control', 'find', 'hypocrit', 'peopl', 'extol', 'right', 'express', 'sexual', 'urg', 'celebr', 'yet', 'close', 'relat', 'urg', 'procreat', 'parent', 'somehow', 'consid"
     ]
    },
    {
     "data": {
      "text/html": [
       "<b>limit_output extension: Maximum message size of 10000 exceeded with 11602 characters</b>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts = processed_threads\n",
    "print('The length of the documents is...')\n",
    "print(len(texts))\n",
    "print('*' * 50)\n",
    "print('the first document is...')\n",
    "print(texts[0])\n",
    "print('*' * 50)\n",
    "\n",
    "print('buiding the dictionary...')\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('MommitDictionary.dict')\n",
    "print(dictionary[0])\n",
    "\n",
    "print('building the corpus')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('MommitCorpusFinal.mm', corpus)\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:44.441152Z",
     "start_time": "2020-02-20T00:22:44.434978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading all LDA models....\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "print('reading all LDA models....')\n",
    "print('*' * 50)\n",
    "\n",
    "model_list =  []\n",
    "\n",
    "coherence_values = []\n",
    "\n",
    "for i in range(0, len(model_list)):\n",
    "    print('now working on coherence value for model...')\n",
    "    print(model_list[i])\n",
    "    print('*' * 50)\n",
    "    coherencemodel = CoherenceModel(model=model_list[i], texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:22:44.449941Z",
     "start_time": "2020-02-20T00:22:44.443551Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:50:40.599661Z",
     "start_time": "2020-02-20T00:22:44.452296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tammari/Desktop/DaskTest/env/lib/python3.6/site-packages/scipy/sparse/lil.py:504: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\n",
      "/Users/tammari/Desktop/DaskTest/env/lib/python3.6/site-packages/scipy/sparse/lil.py:506: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n",
      "  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=corpus, texts=texts, start=10, limit=100, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:50:40.782447Z",
     "start_time": "2020-02-20T00:50:40.602216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(50, 0.3723073201834858), (60, 0.3584696938337278), (80, 0.35344258290129604), (30, 0.3527240830563468), (70, 0.3451880728465597), (90, 0.3434842602732379), (40, 0.3371560677325858), (20, 0.3279863377063672), (10, 0.29906741373226675)]\n",
      "**************************************************\n",
      "Num Topics = 50  has Coherence Value of 0.3723\n",
      "Num Topics = 60  has Coherence Value of 0.3585\n",
      "Num Topics = 80  has Coherence Value of 0.3534\n",
      "Num Topics = 30  has Coherence Value of 0.3527\n",
      "Num Topics = 70  has Coherence Value of 0.3452\n",
      "Num Topics = 90  has Coherence Value of 0.3435\n",
      "Num Topics = 40  has Coherence Value of 0.3372\n",
      "Num Topics = 20  has Coherence Value of 0.328\n",
      "Num Topics = 10  has Coherence Value of 0.2991\n",
      "saving list...\n",
      "**************************************************\n",
      "creating a graph of the coherence model...\n",
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "limit = 100\n",
    "start = 10\n",
    "step  = 10    \n",
    "\n",
    "x = range(start, limit, step)\n",
    "coherence = zip(x, coherence_values)\n",
    "sorted_coherence = sorted(coherence, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(sorted_coherence)\n",
    "print('*' * 50)\n",
    "\n",
    "for m, cv in sorted_coherence:\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))\n",
    "    \n",
    "print('saving list...')\n",
    "print('*' * 50)\n",
    "with open(\"Mommit_cohere.pkl\", \"wb\") as fp: \n",
    "    pickle.dump(sorted_coherence, fp)\n",
    "    \n",
    "print('creating a graph of the coherence model...')\n",
    "print('*' * 50)\n",
    "\n",
    "# Show graph\n",
    "fig = plt.gcf()\n",
    "limit=limit; start=start; step=step;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "fig.savefig('Mommit_LDA_models_coherence.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-20T00:51:30.021186Z",
     "start_time": "2020-02-20T00:51:26.421775Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(model_list)):\n",
    "    model_list[i].save('Mommit_Model'+str(i)+\".model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
